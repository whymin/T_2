{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fce3c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotTree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9e6a5af80e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgroup_11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcaculateAUC_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 建立一棵CART树\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/excretion/T_2/RandomForest-master/group_11/caculateAUC_1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcaculateRFAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# 计算森林中每棵树的AUC并画图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotTree'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from csv import reader\n",
    "from random import randint\n",
    "from random import seed\n",
    " \n",
    "import numpy as np\n",
    "from numpy import mat\n",
    " \n",
    "from group_11 import caculateAUC_1, plotTree\n",
    " \n",
    "# 建立一棵CART树\n",
    "'''试探分枝'''\n",
    "def data_split(index, value, dataset):\n",
    " left, right = list(), list()\n",
    " for row in dataset:\n",
    "  if row[index] < value:\n",
    "   left.append(row)\n",
    "  else:\n",
    "   right.append(row)\n",
    " return left, right\n",
    " \n",
    "'''计算基尼指数'''\n",
    "def calc_gini(groups, class_values):\n",
    " gini = 0.0\n",
    " total_size = 0\n",
    " for group in groups:\n",
    "  total_size += len(group)\n",
    " for group in groups:\n",
    "  size = len(group)\n",
    "  if size == 0:\n",
    "   continue\n",
    "  for class_value in class_values:\n",
    "   proportion = [row[-1] for row in group].count(class_value) / float(size)\n",
    "   gini += (size / float(total_size)) * (proportion * (1.0 - proportion))# 二分类执行两次，相当于*2\n",
    " return gini\n",
    " \n",
    "'''找最佳分叉点'''\n",
    "def get_split(dataset, n_features):\n",
    " class_values = list(set(row[-1] for row in dataset))# 类别标签集合\n",
    " b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    " \n",
    " # 随机选取特征子集，包含n_features个特征\n",
    " features = list()\n",
    " while len(features) < n_features:\n",
    "  # 随机选取特征\n",
    "  # 特征索引\n",
    "  index = randint(0, len(dataset[0]) - 2) # 往features添加n_features个特征（n_feature等于特征数的根号），特征索引从dataset中随机取\n",
    "  if index not in features:\n",
    "   features.append(index)\n",
    " for index in features:  # 对每一个特征\n",
    "  # 计算Gini指数\n",
    "  for row in dataset: # 按照每个记录的该特征的取值划分成两个子集，计算对于的Gini（D，A），取最小的\n",
    "   groups = data_split(index, row[index], dataset)\n",
    "   gini = calc_gini(groups, class_values)\n",
    "   if gini < b_score:\n",
    "    b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    " return {'index': b_index, 'value': b_value, 'groups': b_groups} # 每个节点由字典组成\n",
    " \n",
    "'''多数表决'''\n",
    "def to_terminal(group):\n",
    " outcomes = [row[-1] for row in group]\n",
    " return max(set(outcomes), key=outcomes.count)\n",
    " \n",
    "'''分枝'''\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    " left, right = node['groups'] # 自动分包/切片\n",
    " del (node['groups'])\n",
    " if not left or not right: # left或者right为空时\n",
    "  node['left'] = node['right'] = to_terminal(left + right) # 叶节点不好理解\n",
    "  return\n",
    " \n",
    " if depth >= max_depth:\n",
    "  node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "  return\n",
    " # 左子树\n",
    " if len(left) <= min_size:\n",
    "  node['left'] = to_terminal(left)\n",
    " else:\n",
    "  node['left'] = get_split(left, n_features)\n",
    "  split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    " # 右子树\n",
    " if len(right) <= min_size: # min_size最小的的分枝样本数\n",
    "  node['right'] = to_terminal(right)\n",
    " else:\n",
    "  node['right'] = get_split(right, n_features)\n",
    "  split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    " \n",
    "'''建立一棵树'''\n",
    "def build_one_tree(train, max_depth, min_size, n_features):\n",
    " # 寻找最佳分裂点作为根节点\n",
    " root = get_split(train, n_features)\n",
    " split(root, max_depth, min_size, n_features, 1)\n",
    " return root\n",
    " \n",
    "'''用森林里的一棵树来预测'''\n",
    "def predict(node, row):\n",
    " if row[node['index']] < node['value']:\n",
    "  if isinstance(node['left'], dict):\n",
    "   return predict(node['left'], row)\n",
    "  else:\n",
    "   return node['left']\n",
    " else:\n",
    "  if isinstance(node['right'], dict):\n",
    "   return predict(node['right'], row)\n",
    "  else:\n",
    "   return node['right']\n",
    " \n",
    " \n",
    "# 随机森林类\n",
    "class randomForest:\n",
    " def __init__(self,trees_num, max_depth, leaf_min_size, sample_ratio, feature_ratio):\n",
    "  self.trees_num = trees_num    # 森林的树的数目\n",
    "  self.max_depth = max_depth    # 树深\n",
    "  self.leaf_min_size = leaf_min_size  # 建立树时，停止的分枝样本最小数目\n",
    "  self.samples_split_ratio = sample_ratio # 采样，创建子集的比例（行采样）\n",
    "  self.feature_ratio = feature_ratio  # 特征比例（列采样）\n",
    "  self.trees = list()      # 森林\n",
    " \n",
    " '''有放回的采样，创建数据子集'''\n",
    " def sample_split(self, dataset):\n",
    "  sample = list()\n",
    "  n_sample = round(len(dataset) * self.samples_split_ratio) #每棵树的采样数\n",
    "  while len(sample) < n_sample:\n",
    "   index = randint(0, len(dataset) - 2) #随机有放回的采样\n",
    "   sample.append(dataset[index])\n",
    "  return sample\n",
    " \n",
    " ##############***Out-of-Bag***################################\n",
    " # 进行袋外估计等相关函数的实现,需要注意并不是每个样本都可能出现在随机森林的袋外数据中\n",
    " # 因此进行oob估计时需要注意估计样本的数量\n",
    " def OOB(self, oobdata, train, trees):\n",
    "  '''输入为：袋外数据dict,训练集,tree_list\n",
    "  return oob准确率'''\n",
    " \n",
    "  n_rows = []\n",
    "  count = 0\n",
    "  n_trees = len(trees) # 森林中树的棵树\n",
    " \n",
    "  for key, item in oobdata.items():\n",
    "   n_rows.append(item)\n",
    " \n",
    "  # print(len(n_rows)) # 所有trees中的oob数据的合集\n",
    " \n",
    "  n_rows_list = sum(n_rows, [])\n",
    " \n",
    "  unique_list = []\n",
    "  for l1 in n_rows_list: # 从oob合集中计算独立样本数量\n",
    "   if l1 not in unique_list:\n",
    "    unique_list.append(l1)\n",
    " \n",
    "  n = len(unique_list)\n",
    "  # print(n)\n",
    " \n",
    "  # 对训练集中的每个数据，进行遍历，寻找其作为oob数据时的所有trees,并进行多数投票\n",
    "  for row in train:\n",
    "   pre = []\n",
    "   for i in range(n_trees):\n",
    "    if row not in oobdata[i]:\n",
    "     # print('row: ',row)\n",
    "     # print('trees[i]: ', trees[i])\n",
    "     pre.append(predict(trees[i], row))\n",
    "   if len(pre) > 0:\n",
    "    label = max(set(pre), key=pre.count)\n",
    "    if label == row[-1]:\n",
    "     count += 1\n",
    " \n",
    "  return (float(count) / n) * 100\n",
    " \n",
    " '''建立随机森林'''\n",
    " def build_randomforest(self, train):\n",
    "  temp_flag = 0\n",
    "  max_depth = self.max_depth   # 树深\n",
    "  min_size = self.leaf_min_size  # 建立树时，停止的分枝样本最小数目\n",
    "  n_trees = self.trees_num    # 森林的树的数目\n",
    "  n_features = int(self.feature_ratio * (len(train[0])-1)) #列采样，从M个feature中，选择m个(m<<M)\n",
    "  # print('特征值为 : ',n_features)\n",
    "  oobs = {} # ----------------------\n",
    "  for i in range(n_trees):   # 建立n_trees棵决策树\n",
    "   sample = self.sample_split(train)  # 有放回的采样，创建数据子集\n",
    "   oobs[i] = sample # ----------------\n",
    "   tree = build_one_tree(sample, max_depth, min_size, n_features) # 建立决策树\n",
    "   self.trees.append(tree)\n",
    "   temp_flag += 1\n",
    "   # print(i,tree)\n",
    "  oob_score = self.OOB(oobs, train, self.trees) # oob准确率---------\n",
    "  print(\"oob_score is \", oob_score) # 打印oob准确率---------\n",
    "  return self.trees\n",
    " \n",
    " '''随机森林预测的多数表决'''\n",
    " def bagging_predict(self, onetestdata):\n",
    "  predictions = [predict(tree, onetestdata) for tree in self.trees]\n",
    "  return max(set(predictions), key=predictions.count)\n",
    " \n",
    " '''计算建立的森林的精确度'''\n",
    " def accuracy_metric(self, testdata):\n",
    "  correct = 0\n",
    "  for i in range(len(testdata)):\n",
    "   predicted = self.bagging_predict(testdata[i])\n",
    "   if testdata[i][-1] == predicted:\n",
    "    correct += 1\n",
    "  return correct / float(len(testdata)) * 100.0\n",
    " \n",
    " \n",
    "# 数据处理\n",
    "'''导入数据'''\n",
    "def load_csv(filename):\n",
    " dataset = list()\n",
    " with open(filename, 'r') as file:\n",
    "  csv_reader = reader(file)\n",
    "  for row in csv_reader:\n",
    "   if not row:\n",
    "    continue\n",
    "   # dataset.append(row)\n",
    "   dataset.append(row[:-1])\n",
    " # return dataset\n",
    " return dataset[1:], dataset[0]\n",
    " \n",
    "'''划分训练数据与测试数据'''\n",
    "def split_train_test(dataset, ratio=0.3):\n",
    " #ratio = 0.2 # 取百分之二十的数据当做测试数据\n",
    " num = len(dataset)\n",
    " train_num = int((1-ratio) * num)\n",
    " dataset_copy = list(dataset)\n",
    " traindata = list()\n",
    " while len(traindata) < train_num:\n",
    "  index = randint(0,len(dataset_copy)-1)\n",
    "  traindata.append(dataset_copy.pop(index))\n",
    " testdata = dataset_copy\n",
    " return traindata, testdata\n",
    " \n",
    "'''分析树，将向量内积写入list'''\n",
    "def analyListTree(node, tag, result):\n",
    " # 叶子节点的父节点\n",
    " if (isinstance(node['left'], dict)):\n",
    "  # 计算node与node[tag]的内积\n",
    "  tag=\"left\"\n",
    "  re = Inner_product(node, tag)\n",
    "  result.append(re)\n",
    "  analyListTree(node['left'], 'left', result)\n",
    "  return\n",
    " elif (isinstance(node['right'], dict)):\n",
    "  # 计算node与node[tag]的内积\n",
    "  tag = \"right\"\n",
    "  re = Inner_product(node, tag)\n",
    "  result.append(re)\n",
    "  analyListTree(node['right'], 'right', result)\n",
    "  return\n",
    " else:\n",
    "  return\n",
    " \n",
    "'''求向量内积'''\n",
    "# 计算node与node[tag]的内积\n",
    "def Inner_product(node ,tag):\n",
    " a = mat([[float(node['index'])], [float(node['value'])]])\n",
    " b = mat([[float(node[tag]['index'])], [float(node[tag]['value'])]])\n",
    " return (a.T * b)[0,0]\n",
    " \n",
    "'''相似度优化'''\n",
    "''' same_value = 20  # 向量内积的差（小于此值认为相似）\n",
    " same_rate = 0.63  # 树的相似度（大于此值认为相似）\n",
    " 返回新的森林（已去掉相似度高的树）'''\n",
    "def similarity_optimization(newforest, samevalue, samerate):\n",
    " res = list()    # 存储森林的内积\n",
    " result = list()    # 存储某棵树的内积\n",
    " i = 1\n",
    " for tree in newforest:\n",
    "  # 分析树，将向量内积写入list\n",
    "  # result 存储tree的内积\n",
    "  analyListTree(tree, None, result)\n",
    "  res.append(result)\n",
    "  # print('第',i,'棵树：',len(result),result)\n",
    "  result = []\n",
    " # print('res = ',len(res),res)\n",
    " # 取一棵树的单个向量内积与其他树的单个向量内积做完全对比（相似度）\n",
    " # 遍历列表的列\n",
    " for i in range(0, len(res) - 1):\n",
    "  # 保证此列未被置空、\n",
    "  if not newforest[i] == None:\n",
    "   # 遍历做对比的树的列\n",
    "   for k in range(i + 1, len(res)):\n",
    "    if not newforest[k] == None:\n",
    "     # time用于统计相似的次数，在每次更换对比树时重置为0\n",
    "     time = 0\n",
    "     # 遍历列表的当前行\n",
    "     for j in range(0, len(res[i])):\n",
    "      # 当前两颗树对比次数\n",
    "      all_contrast = (res[ i].__len__() * res[k].__len__())\n",
    "      # 遍历做对比的树的行\n",
    "      for l in range(0, len(res[k])):\n",
    "       # 如果向量的内积相等，计数器加一\n",
    "       if res[i][j] - res[k][l] < samevalue:\n",
    "        time = time + 1\n",
    "      # 如果相似度大于设定值\n",
    "     real_same_rate = time / all_contrast\n",
    "     if (real_same_rate > samerate):\n",
    "      # 将对比树置空\n",
    "      newforest[k] = None\n",
    " result_forest = list()\n",
    " for i in range(0, newforest.__len__()):\n",
    "  if not newforest[i] == None:\n",
    "   result_forest.append(newforest[i])\n",
    " return result_forest\n",
    " \n",
    " \n",
    "'''auc优化method'''\n",
    "def auc_optimization(auclist,trees_num,trees):\n",
    " # 为auc排序，获取从大到小的与trees相对应的索引列表\n",
    " b = sorted(enumerate(auclist), key=lambda x: x[1], reverse=True)\n",
    " index_list = [x[0] for x in b]\n",
    " auc_num = int(trees_num * 2 / 3)\n",
    " # 取auc高的前auc_num个\n",
    " print('auc: ', auc_num, index_list)\n",
    " newTempForest = list()\n",
    " for i in range(auc_num):\n",
    "  # myRF.trees.append(tempForest[i])\n",
    "  # newTempForest.append(myRF.trees[index_list[i]])\n",
    "  newTempForest.append(trees[index_list[i]])\n",
    " return newTempForest\n",
    " \n",
    "'''得到森林中决策树的最佳深度'''\n",
    "def getBestDepth(min_size,sample_ratio,trees_num,feature_ratio,traindata,testdata):\n",
    " max_depth = np.linspace(1, 15, 15, endpoint=True)\n",
    " # max_depth=[5,6,7,8,9,10,11,12,13,14,15]\n",
    " scores_final = []\n",
    " i=0\n",
    " for depth in max_depth:\n",
    "  # 初始化随机森林\n",
    "  # print('=========>',i,'<=============')\n",
    "  myRF_ = randomForest(trees_num, depth, min_size, sample_ratio, feature_ratio)\n",
    "  # 生成随机森林\n",
    "  myRF_.build_randomforest(traindata)\n",
    "  # 测试评估\n",
    "  acc = myRF_.accuracy_metric(testdata[:-1])\n",
    "  # print('模型准确率：', acc, '%')\n",
    "  # scores_final.append(acc.mean())\n",
    "  scores_final.append(acc*0.01)\n",
    "  i=i+1\n",
    " # print('scores_final: ',scores_final)\n",
    " # 找到深度小且准确率高的值\n",
    " best_depth = 0\n",
    " temp_score = 0\n",
    " for i in range(len(scores_final)):\n",
    "  if scores_final[i] > temp_score:\n",
    "   temp_score = scores_final[i]\n",
    "   best_depth = max_depth[i]\n",
    " # print('best_depth:',np.mean(scores_final),best_depth)\n",
    " # plt.plot(max_depth, scores_final, 'r-', lw=2)\n",
    " # # plt.plot(max_depth, list(range(0,max(scores_final))), 'r-', lw=2)\n",
    " # plt.xlabel('max_depth')\n",
    " # plt.ylabel('CV scores')\n",
    " # plt.ylim(bottom=0.0,top=1.0)\n",
    " # plt.grid()\n",
    " # plt.show()\n",
    " return best_depth\n",
    " \n",
    " \n",
    "'''对比不同树个数时的模型正确率'''\n",
    "def getMyRFAcclist(treenum_list):\n",
    " seed(1) # 每一次执行本文件时都能产生同一个随机数\n",
    " filename = 'DataSet3.csv'   #SMOTE处理过的数据\n",
    " min_size = 1\n",
    " sample_ratio = 1\n",
    " feature_ratio = 0.3 # 尽可能小，但是要保证 int(self.feature_ratio * (len(train[0])-1)) 大于1\n",
    " same_value = 20 # 向量内积的差（小于此值认为相似）\n",
    " same_rate = 0.63 # 树的相似度（大于此值认为相似）\n",
    " \n",
    " # 加载数据\n",
    " dataset, features = load_csv(filename)\n",
    " traindata, testdata = split_train_test(dataset, feature_ratio)\n",
    " # 森林中不同树个数的对比\n",
    " # treenum_list = [20, 30, 40, 50, 60]\n",
    " acc_num_list = list()\n",
    " acc_list=list()\n",
    " for trees_num in treenum_list:\n",
    "  # 优化1-获取最优深度\n",
    "  max_depth = getBestDepth(min_size, sample_ratio, trees_num, feature_ratio, traindata, testdata)\n",
    "  print('max_depth is ', max_depth)\n",
    " \n",
    "  # 初始化随机森林\n",
    "  myRF = randomForest(trees_num, max_depth, min_size, sample_ratio, feature_ratio)\n",
    "  # 生成随机森林\n",
    "  myRF.build_randomforest(traindata)\n",
    " \n",
    "  print('Tree_number: ', myRF.trees.__len__())\n",
    "  # 计算森林中每棵树的AUC\n",
    "  auc_list = caculateAUC_1.caculateRFAUC(testdata, myRF.trees)\n",
    "  # 选取AUC高的决策数形成新的森林(auc优化)\n",
    "  newTempForest = auc_optimization(auc_list,trees_num,myRF.trees)\n",
    "  # 相似度优化\n",
    "  myRF.trees = similarity_optimization(newTempForest, same_value, same_rate)\n",
    "  # 测试评估\n",
    "  acc = myRF.accuracy_metric(testdata[:-1])\n",
    "  print('myRF1_模型准确率：', acc, '%')\n",
    "  acc_num_list.append([myRF.trees.__len__(), acc])\n",
    "  acc_list.append(acc)\n",
    " print('trees_num from 20 to 60: ', acc_num_list)\n",
    " return acc_list\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    " start = time.clock()\n",
    " seed(1) # 每一次执行本文件时都能产生同一个随机数\n",
    " filename = 'DataSet3.csv'  # 这里是已经利用SMOTE进行过预处理的数据集\n",
    " max_depth = 15 # 调参（自己修改） #决策树深度不能太深，不然容易导致过拟合\n",
    " min_size = 1\n",
    " sample_ratio = 1\n",
    " trees_num = 20\n",
    " \n",
    " feature_ratio = 0.3  # 尽可能小，但是要保证 int(self.feature_ratio * (len(train[0])-1)) 大于1\n",
    " same_value = 20  # 向量内积的差（小于此值认为相似）\n",
    " same_rate = 0.82  # 树的相似度（大于此值认为相似）\n",
    " # 加载数据\n",
    " dataset,features = load_csv(filename)\n",
    " traindata,testdata = split_train_test(dataset, feature_ratio)\n",
    " \n",
    " # 优化1-获取最优深度\n",
    " # max_depth = getBestDepth(min_size, sample_ratio, trees_num, feature_ratio, traindata, testdata)\n",
    " # print('max_depth is ',max_depth)\n",
    " \n",
    " # 初始化随机森林\n",
    " myRF = randomForest(trees_num, max_depth, min_size, sample_ratio, feature_ratio)\n",
    " # 生成随机森林\n",
    " myRF.build_randomforest(traindata)\n",
    " \n",
    " print('Tree_number: ', myRF.trees.__len__())\n",
    " acc = myRF.accuracy_metric(testdata[:-1])\n",
    " print('传统RF模型准确率：',acc,'%')\n",
    " \n",
    " # 画出某棵树用以可视化观察（这里是第一棵树）\n",
    " # plotTree.creatPlot(myRF.trees[0], features)\n",
    " # 计算森林中每棵树的AUC\n",
    " auc_list = caculateAUC_1.caculateRFAUC(testdata,myRF.trees)\n",
    " # 画出每棵树的auc——柱状图\n",
    " # plotTree.plotAUCbar(auc_list.__len__(),auc_list)\n",
    " \n",
    " # 选取AUC高的决策数形成新的森林(auc优化)\n",
    " newTempForest = auc_optimization(auc_list,trees_num,myRF.trees)\n",
    " # 相似度优化\n",
    " myRF.trees=similarity_optimization(newTempForest, same_value, same_rate)\n",
    " \n",
    " print('优化后Tree_number: ', myRF.trees.__len__())\n",
    " # 测试评估\n",
    " acc = myRF.accuracy_metric(testdata[:-1])\n",
    " # print('优化后模型准确率：', acc, '%')\n",
    " print('myRF1_模型准确率：', acc, '%')\n",
    " # 画出某棵树用以可视化观察（这里是第一棵树）\n",
    " # plotTree.creatPlot(myRF.trees[0], features)\n",
    " # 计算森林中每棵树的AUC\n",
    " auc_list = caculateAUC_1.caculateRFAUC(testdata, myRF.trees)\n",
    " # 画出每棵树的auc——柱状图\n",
    " plotTree.plotAUCbar(auc_list.__len__(), auc_list)\n",
    " end = time.clock()\n",
    " print('The end!')\n",
    " print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a9c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
